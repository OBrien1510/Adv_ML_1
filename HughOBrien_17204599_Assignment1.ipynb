{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP47590: Advanced Machine Learning\n",
    "# Assignment 1: Building Stacked Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name(s): Hugh O'Brien\n",
    "\n",
    "Student Number(s): 17204599"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages Etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Image\n",
    "\n",
    "#from TAS_Python_Utilities import data_viz\n",
    "#from TAS_Python_Utilities import data_viz_target\n",
    "#from TAS_Python_Utilities import visualize_tree\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from random import randint\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.spatial import distance\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "#%qtconsole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define StackedEnsembleClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function to create classifer objects based on a name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_classifier(classifier_type, tree_min_samples_split = 20):\n",
    "\n",
    "    if classifier_type == \"svm\":\n",
    "        c = svm.SVC(probability=True)\n",
    "\n",
    "    elif classifier_type == \"logreg\":\n",
    "        c = linear_model.LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=1000)\n",
    "\n",
    "    elif classifier_type == \"knn\":\n",
    "        c = neighbors.KNeighborsClassifier()\n",
    "\n",
    "    elif classifier_type == \"tree\":\n",
    "        c = tree.DecisionTreeClassifier(min_samples_split = tree_min_samples_split)\n",
    "\n",
    "    elif classifier_type == \"randomforest\":\n",
    "        c = ensemble.RandomForestClassifier()\n",
    "        \n",
    "    else:\n",
    "        c = linear_model.LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=1000)\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StackedEnsembleClassifier class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new classifier which is based on the sckit-learn BaseEstimator and ClassifierMixin classes\n",
    "class StackedEnsembleClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer and a aggregatnio model at the aggregation layer. A k-fold cross validation is used to gnerate training data for the stack layer model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimators: list \n",
    "        A list of the classifiers in the ase layer of the ensemble. Supported types are\n",
    "        - \"svm\" Support Vector Machine implemented by sklearn.svm.SVC\n",
    "        - \"logreg\" Logistic Regression implemented by sklearn.linear_models.LogisticRegression\n",
    "        - \"knn\" k Nearest Neighbour implemented by sklearn.neighbors.KNeighborsClassifier\n",
    "        - \"tree\" Decision Tree implemented by sklearn.tree.DecisionTreeClassifier\n",
    "        - \"randomforest\" RandomForest implemented by sklearn.tree.RandomForestClassifier    \n",
    "    classifier_duplicates: int, optional (default = 1)\n",
    "        How many instances of each classifier type listed in base_estimators is included in the ensemble\n",
    "    stack_layer_classifier: string, optional (default = \"logreg')\n",
    "        The classifier type used at the stack layer. The same classifier types as are supported at the base layer are supported        \n",
    "    training_folds: int, optional (default = 4)\n",
    "        How many folds will be used to generate the training set for the stacked layer\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : array of shape = [n_classes] \n",
    "        The classes labels (single output problem).\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The default values for most base learners are used.\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "    ----------\n",
    "    .. [1]  van der Laan, M., Polley, E. & Hubbard, A. (2007). \n",
    "            Super Learner. Statistical Applications in Genetics \n",
    "            and Molecular Biology, 6(1) \n",
    "            doi:10.2202/1544-6115.1309\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = StackedEnsembleClassifier()\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, base_estimator_types = [\"svm\", \"logreg\", \"tree\"], base_estimator_duplicates = 8, stack_layer_classifier_type = \"logreg\"):\n",
    "        \"\"\"Setup a SuperLearner classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator_types: The types of classifiers to include at the base layer\n",
    "        base_estimator_duplicates: The number of duplicates of each type of classiifer to include\n",
    "        stack_layer_classifier_type: The type of classifier to include at the stack layer \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Nothing\n",
    "        \"\"\"     \n",
    "\n",
    "        # Initialise class variabels\n",
    "        self.base_estimator_types = base_estimator_types\n",
    "        self.base_estimator_type_list = list()\n",
    "        self.base_estimator_duplicates = base_estimator_duplicates\n",
    "        self.stack_layer_classifier_type = stack_layer_classifier_type\n",
    "\n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build a SuperLearner classifier from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            The training input samples. \n",
    "        y : array-like, shape = [n_samples] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"    \n",
    "        \n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "        \n",
    "        ########################\n",
    "        # LEVEL 0\n",
    "        ########################\n",
    "        \n",
    "        # Set up the base classifeirs in the ensemble\n",
    "        self.classifiers_ = list()\n",
    "        \n",
    "        for i in range(0, self.base_estimator_duplicates):\n",
    "            for t in self.base_estimator_types:\n",
    "\n",
    "                self.base_estimator_type_list.append(t)      \n",
    "                c = create_classifier(t, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "                self.classifiers_.append(c)\n",
    "        \n",
    "        # Store the number of classifers in the ensemble\n",
    "        self.n_estimators_ = len(self.classifiers_)\n",
    "\n",
    "        # Use all training data to train base classifiers\n",
    "        X_train = X\n",
    "        y_train = y\n",
    "        \n",
    "        # Set up empty arrays to hold stack layer training data\n",
    "        self.X_stack_train = None #(dtype = float)\n",
    "        self.y_stack_train = y_train\n",
    "          \n",
    "        # Train each base calssifier and generate the stack layer training dataset\n",
    "        for classifier in self.classifiers_:\n",
    "\n",
    "            # Extract a bootstrap sample\n",
    "            X_train_samp, y_train_samp = resample(X_train, y_train, replace=True)    \n",
    "            \n",
    "            # Train a base classifier\n",
    "            classifier.fit(X_train_samp, y_train_samp)\n",
    "            \n",
    "            # Make predictions for all instances in the training set\n",
    "            y_pred = classifier.predict_proba(X_train)\n",
    "\n",
    "            # Append the predictions ot the stack layer traing set (a bit of hacking here!)\n",
    "            try:\n",
    "                self.X_stack_train = np.c_[self.X_stack_train, y_pred]\n",
    "            except ValueError:\n",
    "                self.X_stack_train = y_pred\n",
    "      \n",
    "        ########################\n",
    "        # LEVEL 1\n",
    "        ########################\n",
    "        \n",
    "        # Create the stack layer classifier\n",
    "        self.stack_layer_classifier_ = create_classifier(self.stack_layer_classifier_type, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "\n",
    "        # Train the stack layer using the newly created dataset\n",
    "        self.stack_layer_classifier_.fit(self.X_stack_train, self.y_stack_train)\n",
    "            \n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, ].\n",
    "            The predicted class labels of the input samples. \n",
    "        \"\"\"\n",
    "        \n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "   \n",
    "        X_stack_queries = None\n",
    "              \n",
    "        # Make a prediction with each base classifier and assemble the stack layer query\n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)\n",
    "            \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "        \n",
    "        # Return the prediction made by the stack layer classifier\n",
    "        return self.stack_layer_classifier_.predict(X_stack_queries)\n",
    "    \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, n_labels].\n",
    "            The predicted class label probabilities of the input samples. \n",
    "        \"\"\"\n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "        \n",
    "        X_stack_queries = None\n",
    "        \n",
    "        # Make a prediction with each base classifier\n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)\n",
    "                \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "\n",
    "        # Return the prediction made by the stack layer classifier        \n",
    "        return self.stack_layer_classifier_.predict_proba(X_stack_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the StackedEnsembleClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a simple test using the StackedEnsembleClassifier on the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        50\n",
      "          1       1.00      0.96      0.98        50\n",
      "          2       0.96      1.00      0.98        50\n",
      "\n",
      "avg / total       0.99      0.99      0.99       150\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2  All\n",
       "True                      \n",
       "0          50   0   0   50\n",
       "1           0  48   2   50\n",
       "2           0   0  50   50\n",
       "All        50  48  52  150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "clf = StackedEnsembleClassifier()\n",
    "clf.fit(iris.data, iris.target)\n",
    "y_pred = clf.predict(iris.data)\n",
    "print(metrics.classification_report(iris.target, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(iris.target), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a cross validation experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          0.93333333  1.          0.93333333  0.93333333  0.93333333\n",
      "  0.86666667  1.          1.          1.        ]\n",
      "0.96  +/-  0.0442216638714\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "print(scores)\n",
    "print(np.mean(scores), \" +/- \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Design the StackedEnsembleHoldOut Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StackedEnsembleClassifierHoldOut(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer and a aggregatnio model at the aggregation layer. A k-fold cross validation is used to gnerate training data for the stack layer model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimators: list \n",
    "        A list of the classifiers in the ase layer of the ensemble. Supported types are\n",
    "        - \"svm\" Support Vector Machine implemented by sklearn.svm.SVC\n",
    "        - \"logreg\" Logistic Regression implemented by sklearn.linear_models.LogisticRegression\n",
    "        - \"knn\" k Nearest Neighbour implemented by sklearn.neighbors.KNeighborsClassifier\n",
    "        - \"tree\" Decision Tree implemented by sklearn.tree.DecisionTreeClassifier\n",
    "        - \"randomforest\" RandomForest implemented by sklearn.tree.RandomForestClassifier    \n",
    "    classifier_duplicates: int, optional (default = 1)\n",
    "        How many instances of each classifier type listed in base_estimators is included in the ensemble\n",
    "    stack_layer_classifier: string, optional (default = \"logreg')\n",
    "        The classifier type used at the stack layer. The same classifier types as are supported at the base layer are supported        \n",
    "    training_folds: int, optional (default = 4)\n",
    "        How many folds will be used to generate the training set for the stacked layer\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : array of shape = [n_classes] \n",
    "        The classes labels (single output problem).\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The default values for most base learners are used.\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "    ----------\n",
    "    .. [1]  van der Laan, M., Polley, E. & Hubbard, A. (2007). \n",
    "            Super Learner. Statistical Applications in Genetics \n",
    "            and Molecular Biology, 6(1) \n",
    "            doi:10.2202/1544-6115.1309\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = StackedEnsembleClassifier()\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, base_estimator_types = [\"svm\", \"logreg\", \"tree\"], base_estimator_duplicates = 8, stack_layer_classifier_type = \"logreg\"):\n",
    "        \"\"\"Setup a SuperLearner classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator_types: The types of classifiers to include at the base layer\n",
    "        base_estimator_duplicates: The number of duplicates of each type of classiifer to include\n",
    "        stack_layer_classifier_type: The type of classifier to include at the stack layer \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Nothing\n",
    "        \"\"\"     \n",
    "\n",
    "        # Initialise class variabels\n",
    "        self.base_estimator_types = base_estimator_types\n",
    "        self.base_estimator_type_list = list()\n",
    "        self.base_estimator_duplicates = base_estimator_duplicates\n",
    "        self.stack_layer_classifier_type = stack_layer_classifier_type\n",
    "\n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build a SuperLearner classifier from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            The training input samples. \n",
    "        y : array-like, shape = [n_samples] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"    \n",
    "        \n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "        \n",
    "        ########################\n",
    "        # LEVEL 0\n",
    "        ########################\n",
    "        \n",
    "        # Set up the base classifeirs in the ensemble\n",
    "        self.classifiers_ = list()\n",
    "        \n",
    "        for i in range(0, self.base_estimator_duplicates):\n",
    "            for t in self.base_estimator_types:\n",
    "\n",
    "                self.base_estimator_type_list.append(t)      \n",
    "                c = create_classifier(t, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "                self.classifiers_.append(c)\n",
    "        \n",
    "        # Store the number of classifers in the ensemble\n",
    "        self.n_estimators_ = len(self.classifiers_)\n",
    "\n",
    "        # Use all training data to train base classifiers\n",
    "        # Perfrom split to train, validation, test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size = 0.30, train_size = 0.7)\n",
    "        \n",
    "        # Set up empty arrays to hold stack layer training data\n",
    "        self.X_stack_train = None #(dtype = float)\n",
    "        self.y_stack_train = y_test\n",
    "          \n",
    "        # Train each base calssifier and generate the stack layer training dataset\n",
    "        for classifier in self.classifiers_:\n",
    "\n",
    "            samples  = int(len(X_train) * 0.7)\n",
    "           \n",
    "            # Extract a bootstrap sample\n",
    "            X_train_samp, y_train_samp = resample(X_train, y_train, replace=True, n_samples = samples)    \n",
    "            \n",
    "            # Train a base classifier\n",
    "            classifier.fit(X_train_samp, y_train_samp)\n",
    "            \n",
    "            # Make predictions for all instances in the training set\n",
    "            y_pred = classifier.predict_proba(X_test)\n",
    "\n",
    "            # Append the predictions ot the stack layer traing set (a bit of hacking here!)\n",
    "            try:\n",
    "                self.X_stack_train = np.c_[self.X_stack_train, y_pred]\n",
    "            except ValueError:\n",
    "                self.X_stack_train = y_pred\n",
    "      \n",
    "        ########################\n",
    "        # LEVEL 1\n",
    "        ########################\n",
    "        \n",
    "        # Create the stack layer classifier\n",
    "        self.stack_layer_classifier_ = create_classifier(self.stack_layer_classifier_type, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "\n",
    "        # Train the stack layer using the newly created dataset\n",
    "        self.stack_layer_classifier_.fit(self.X_stack_train, self.y_stack_train)\n",
    "            \n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, ].\n",
    "            The predicted class labels of the input samples. \n",
    "        \"\"\"\n",
    "        \n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "   \n",
    "        X_stack_queries = None\n",
    "              \n",
    "        # Make a prediction with each base classifier and assemble the stack layer query\n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)\n",
    "            \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "        \n",
    "        \n",
    "        # Return the prediction made by the stack layer classifier\n",
    "        return self.stack_layer_classifier_.predict(X_stack_queries)\n",
    "    \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, n_labels].\n",
    "            The predicted class label probabilities of the input samples. \n",
    "        \"\"\"\n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "        \n",
    "        X_stack_queries = None\n",
    "        \n",
    "        # Make a prediction with each base classifier\n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)\n",
    "                \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "\n",
    "        # Return the prediction made by the stack layer classifier        \n",
    "        return self.stack_layer_classifier_.predict_proba(X_stack_queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        50\n",
      "          1       0.96      0.94      0.95        50\n",
      "          2       0.94      0.96      0.95        50\n",
      "\n",
      "avg / total       0.97      0.97      0.97       150\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2  All\n",
       "True                      \n",
       "0          50   0   0   50\n",
       "1           0  47   3   50\n",
       "2           0   2  48   50\n",
       "All        50  49  51  150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clfho = StackedEnsembleClassifierHoldOut()\n",
    "clfho.fit(iris.data, iris.target)\n",
    "y_pred = clfho.predict(iris.data)\n",
    "print(metrics.classification_report(iris.target, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(iris.target), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Design the StackedEnsembleKFold Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StackedEnsembleClassifierKFold(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer and a aggregatnio model at the aggregation layer. A k-fold cross validation is used to gnerate training data for the stack layer model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimators: list \n",
    "        A list of the classifiers in the ase layer of the ensemble. Supported types are\n",
    "        - \"svm\" Support Vector Machine implemented by sklearn.svm.SVC\n",
    "        - \"logreg\" Logistic Regression implemented by sklearn.linear_models.LogisticRegression\n",
    "        - \"knn\" k Nearest Neighbour implemented by sklearn.neighbors.KNeighborsClassifier\n",
    "        - \"tree\" Decision Tree implemented by sklearn.tree.DecisionTreeClassifier\n",
    "        - \"randomforest\" RandomForest implemented by sklearn.tree.RandomForestClassifier    \n",
    "    classifier_duplicates: int, optional (default = 1)\n",
    "        How many instances of each classifier type listed in base_estimators is included in the ensemble\n",
    "    stack_layer_classifier: string, optional (default = \"logreg')\n",
    "        The classifier type used at the stack layer. The same classifier types as are supported at the base layer are supported        \n",
    "    training_folds: int, optional (default = 4)\n",
    "        How many folds will be used to generate the training set for the stacked layer\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : array of shape = [n_classes] \n",
    "        The classes labels (single output problem).\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The default values for most base learners are used.\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "    ----------\n",
    "    .. [1]  van der Laan, M., Polley, E. & Hubbard, A. (2007). \n",
    "            Super Learner. Statistical Applications in Genetics \n",
    "            and Molecular Biology, 6(1) \n",
    "            doi:10.2202/1544-6115.1309\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = StackedEnsembleClassifier()\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, base_estimator_types = [\"svm\", \"logreg\", \"tree\"], base_estimator_duplicates = 3, stack_layer_classifier_type = \"logreg\"):\n",
    "        \"\"\"Setup a SuperLearner classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator_types: The types of classifiers to include at the base layer\n",
    "        base_estimator_duplicates: The number of duplicates of each type of classiifer to include\n",
    "        stack_layer_classifier_type: The type of classifier to include at the stack layer \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Nothing\n",
    "        \"\"\"     \n",
    "\n",
    "        # Initialise class variabels\n",
    "        self.base_estimator_types = base_estimator_types\n",
    "        self.base_estimator_type_list = list()\n",
    "        self.base_estimator_duplicates = base_estimator_duplicates\n",
    "        self.stack_layer_classifier_type = stack_layer_classifier_type\n",
    "\n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        \"\"\"Build a SuperLearner classifier from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            The training input samples. \n",
    "        y : array-like, shape = [n_samples] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"    \n",
    "        \n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "        \n",
    "        ########################\n",
    "        # LEVEL 0\n",
    "        ########################\n",
    "        \n",
    "        # Set up the base classifeirs in the ensemble\n",
    "        self.classifiers_ = list()\n",
    "        \n",
    "        for i in range(0, self.base_estimator_duplicates):\n",
    "            for t in self.base_estimator_types:\n",
    "\n",
    "                self.base_estimator_type_list.append(t)      \n",
    "                c = create_classifier(t, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "                self.classifiers_.append(c)\n",
    "        \n",
    "        # Store the number of classifers in the ensemble\n",
    "        self.n_estimators_ = len(self.classifiers_)\n",
    "        \n",
    "        # Set up empty arrays to hold stack layer training data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size = 0.30, train_size = 0.7)\n",
    "        self.X_stack_train = None #(dtype = float)\n",
    "        self.X_stack_train_fold = None\n",
    "        self.y_stack_train = None\n",
    "\n",
    "        # Use all training data to train base classifiers\n",
    "        # Perfrom split to train, validation, test\n",
    "        k = 5\n",
    "        kf = KFold(n_splits=k, random_state=None, shuffle=False)\n",
    "        n = kf.get_n_splits(X)\n",
    "        \n",
    "        multiple_classes = False\n",
    "        \n",
    "        #make sure that each fold has atleast one class type\n",
    "        \n",
    "        while not multiple_classes:\n",
    "    \n",
    "            rng_state = np.random.get_state()\n",
    "            np.random.shuffle(X)\n",
    "            np.random.set_state(rng_state)\n",
    "            np.random.shuffle(y)\n",
    "            np.random.seed(randint(0,101))\n",
    "        \n",
    "            for train_index, test_index in kf.split(X):\n",
    "                \n",
    "                y_train_test = y[train_index]\n",
    "                \n",
    "                if len(np.unique(y_train)) <= 1:\n",
    "                    \n",
    "                    print(y_train)\n",
    "                    multiple_classes = False\n",
    "                    break\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    multiple_classes = True\n",
    "\n",
    "        self.fitted_classifiers = list()\n",
    "        \n",
    "        self.X_stack_train = None\n",
    "        self.y_stack_train = None\n",
    "        \n",
    "        #initialize array to hold all the cross val predictions for each classifier\n",
    "        #column for each classifier\n",
    "        #row for each fold\n",
    "        for i, classifier in enumerate(self.classifiers_):\n",
    "            \n",
    "            #take around 60% for bootstrap sample\n",
    "            samples  = int(len(X_train) * 0.6)\n",
    "           \n",
    "            #get bootstrap sample\n",
    "            X_train_samp, y_train_samp = resample(X_train, y_train, replace=True, random_state=randint(0,101), n_samples = samples)   \n",
    "            \n",
    "            # Train a base classifier\n",
    "            classifier.fit(X_train_samp, y_train_samp)\n",
    "            \n",
    "            #create array to hold complete fold predictions for each classifier\n",
    "            fold_predictions = []\n",
    "            y_folds = []\n",
    "            \n",
    "            k_count = 0\n",
    "            \n",
    "            n = kf.get_n_splits(X)\n",
    "            \n",
    "            #loop through cross validation\n",
    "            for training_index, training_index in kf.split(X):\n",
    "                \n",
    "                #get kfold splits\n",
    "                X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "                y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "                \n",
    "                # for each fold train a base classifier on the training fold\n",
    "                classifier.fit(X_train_fold, y_train_fold)\n",
    "                \n",
    "                #make predictions using the test fold\n",
    "                y_pred = classifier.predict(X_test_fold)\n",
    "                \n",
    "                #add predictions to the classifier's prediction \n",
    "                fold_predictions = fold_predictions + list(y_pred)\n",
    "                \n",
    "                #create vector to old all fold's y values in correct order\n",
    "                y_folds = y_folds + list(y_test_fold)\n",
    "                \n",
    "            \n",
    "            fold_predictions = np.asarray(fold_predictions)\n",
    "            \n",
    "            y_folds = np.asarray(y_folds)\n",
    "            \n",
    "            try:\n",
    "                #append classifiers full fold predictions to matrix\n",
    "                self.X_stack_train =  np.c_[self.X_stack_train, fold_predictions]\n",
    "                \n",
    "            except ValueError:\n",
    "                \n",
    "                self.X_stack_train = fold_predictions\n",
    "                self.Y_stack_train = y_folds\n",
    "                \n",
    "                    \n",
    "        ########################\n",
    "        # LEVEL 1\n",
    "        ########################\n",
    "        \n",
    "        # Create the stack layer classifier\n",
    "        self.stack_layer_classifier_ = create_classifier(self.stack_layer_classifier_type, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "\n",
    "        # Train the stack layer using the newly created dataset\n",
    "        self.stack_layer_classifier_.fit(self.X_stack_train, self.Y_stack_train)\n",
    "            \n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, ].\n",
    "            The predicted class labels of the input samples. \n",
    "        \"\"\"\n",
    "        \n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "    \n",
    "        X_stack_queries = None\n",
    "              \n",
    "        # Make a prediction with each base classifier and assemble the stack layer query\n",
    "        for i, classifier in enumerate(self.classifiers_):\n",
    "            \n",
    "            y_pred = classifier.predict(X)\n",
    "            \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "        \n",
    "        # Return the prediction made by the stack layer classifier\n",
    "        return self.stack_layer_classifier_.predict(X_stack_queries)\n",
    "    \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, n_labels].\n",
    "            The predicted class label probabilities of the input samples. \n",
    "        \"\"\"\n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "        \n",
    "        X_stack_queries = None\n",
    "        \n",
    "        # Make a prediction with each base classifier\n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)\n",
    "                \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "\n",
    "        # Return the prediction made by the stack layer classifier        \n",
    "        return self.stack_layer_classifier_.predict_proba(X_stack_queries)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        50\n",
      "          1       1.00      0.98      0.99        50\n",
      "          2       0.98      1.00      0.99        50\n",
      "\n",
      "avg / total       0.99      0.99      0.99       150\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2  All\n",
       "True                      \n",
       "0          50   0   0   50\n",
       "1           0  49   1   50\n",
       "2           0   0  50   50\n",
       "All        50  49  51  150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clfcv = StackedEnsembleClassifierKFold(base_estimator_duplicates=8)\n",
    "clfcv.fit(iris.data, iris.target)\n",
    "y_pred = clfcv.predict(iris.data)\n",
    "print(metrics.classification_report(iris.target, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(iris.target), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Compare the Performance of Different Stack Layer Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Tests w/ logreg stack layer\n",
      "----------------------\n",
      "Basic Stack Ensemble\n",
      "0.961411564626\n",
      "\n",
      "Hold Out Stacked Ensemble\n",
      "0.968307823129\n",
      "\n",
      "Cross Val Stacked Ensemble\n",
      "0.883214285714\n",
      "\n",
      "Cross Validation Tests w/ svm stack layer\n",
      "----------------------\n",
      "Basic Stack Ensemble\n",
      "0.965255102041\n",
      "\n",
      "Hold Out Stacked Ensemble\n",
      "0.965365646259\n",
      "\n",
      "Cross Val Stacked Ensemble\n",
      "0.964175170068\n",
      "\n",
      "Cross Validation Tests w/ tree stack layer\n",
      "----------------------\n",
      "Basic Stack Ensemble\n",
      "0.963146258503\n",
      "\n",
      "Hold Out Stacked Ensemble\n",
      "0.956641156463\n",
      "\n",
      "Cross Val Stacked Ensemble\n",
      "0.958826530612\n",
      "\n",
      "Cross Validation Tests w/ randomForest stack layer\n",
      "----------------------\n",
      "Basic Stack Ensemble\n",
      "0.962015306122\n",
      "\n",
      "Hold Out Stacked Ensemble\n",
      "0.968988095238\n",
      "\n",
      "Cross Val Stacked Ensemble\n",
      "0.876292517007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs = [\"logreg\",\"svm\",\"tree\", \"randomForest\"]\n",
    "\n",
    "#do cross val test for each different stack classifier\n",
    "for i in gs:\n",
    "    clf = StackedEnsembleClassifier(base_estimator_duplicates=5, base_estimator_types = [\"svm\", \"logreg\", \"tree\", \"knn\", \"randomForest\"], stack_layer_classifier_type=i)\n",
    "    clfho = StackedEnsembleClassifierHoldOut(base_estimator_duplicates=5, base_estimator_types = [\"svm\", \"logreg\", \"tree\", \"knn\", \"randomForest\"], stack_layer_classifier_type=i)\n",
    "    clfcv = StackedEnsembleClassifierKFold(base_estimator_duplicates=5, base_estimator_types = [\"svm\", \"logreg\", \"tree\", \"knn\", \"randomForest\"], stack_layer_classifier_type=i)\n",
    "    print(\"Cross Validation Tests w/\", i, \"stack layer\")\n",
    "    print(\"----------------------\")\n",
    "    \n",
    "    \n",
    "    #due to bagging, the model fit can change by a few decimals from fit to fit\n",
    "    #so perform 100 test and average the results\n",
    "    \n",
    "    print(\"Basic Stack Ensemble\")\n",
    "    total = 0\n",
    "    for i in range(0,100):\n",
    "        total += sum(cross_val_score(clf, iris.data, iris.target, cv=7))/7\n",
    "        \n",
    "    print(total/100)\n",
    "    print()\n",
    "    print(\"Hold Out Stacked Ensemble\")\n",
    "    total = 0\n",
    "    for i in range(0,100):\n",
    "        total += sum(cross_val_score(clfho, iris.data, iris.target, cv=7))/7\n",
    "        \n",
    "    print(total/100)\n",
    "    print()\n",
    "    print(\"Cross Val Stacked Ensemble\")\n",
    "    total = 0\n",
    "    for i in range(0,100):\n",
    "        total += sum(cross_val_score(clfcv, iris.data, iris.target, cv=7))/7\n",
    "        \n",
    "    print(total/100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Comparing the Performance of Different Stack Layer Approaches with  More Standard Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score for GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_neighbors': (2, 3, 4), 'weights': ('uniform', 'distance')},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0) model\n",
      "-------------------\n",
      "0.96768707483\n",
      "\n",
      "Cross Validation score for GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'min_samples_split': (2, 5, 10, 20, 30), 'max_depth': (5, 10, 20)},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0) model\n",
      "-------------------\n",
      "0.954081632653\n",
      "\n",
      "Cross Validation score for GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'solver': ('liblinear', 'newton-cg', 'lbfgs', 'sag'), 'max_iter': (50, 100, 500, 1000)},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0) model\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.934523809524\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/hugh/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "logreg = linear_model.LogisticRegression()\n",
    "\n",
    "knn_params = {\n",
    "    \"n_neighbors\" : (2,3,4),\n",
    "    \"weights\": (\"uniform\", \"distance\"),\n",
    "}\n",
    "\n",
    "dt_params = {\n",
    "    \"min_samples_split\":(2,5,10,20,30),\n",
    "    \"max_depth\": (5,10,20)\n",
    "}\n",
    "\n",
    "log_params = {\n",
    "    \"solver\":(\"liblinear\",\"newton-cg\",\"lbfgs\",\"sag\"),\n",
    "    \"max_iter\": (50,100,500,1000),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "knn = GridSearchCV(knn, knn_params, cv=5)\n",
    "dt = GridSearchCV(dt, dt_params, cv=5)\n",
    "logreg = GridSearchCV(logreg, log_params, cv=5)\n",
    "\n",
    "models = [knn, dt, logreg]\n",
    "\n",
    "for i in models:\n",
    "    \n",
    "    print(\"Cross Validation score for\", i, \"model\")\n",
    "    print(\"-------------------\")\n",
    "    print(sum(cross_val_score(i, iris.data, iris.target, cv=7))/7)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Implement the StackedEnsembleOneVsOne Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StackedEnsembleClassifierOneVsOne(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer and a aggregatnio model at the aggregation layer. A k-fold cross validation is used to gnerate training data for the stack layer model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimators: string \n",
    "        supported types are\n",
    "        - \"svm\" Support Vector Machine implemented by sklearn.svm.SVC\n",
    "        - \"logreg\" Logistic Regression implemented by sklearn.linear_models.LogisticRegression\n",
    "        - \"knn\" k Nearest Neighbour implemented by sklearn.neighbors.KNeighborsClassifier\n",
    "        - \"tree\" Decision Tree implemented by sklearn.tree.DecisionTreeClassifier\n",
    "        - \"randomforest\" RandomForest implemented by sklearn.tree.RandomForestClassifier    \n",
    "    stack_layer_classifier: string, optional (default = \"logreg')\n",
    "        The classifier type used at the stack layer. The same classifier types as are supported at the base layer are supported        \n",
    "    training_folds: int, optional (default = 4)\n",
    "        How many folds will be used to generate the training set for the stacked layer\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : array of shape = [n_classes] \n",
    "        The classes labels (single output problem).\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The default values for most base learners are used.\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "    ----------\n",
    "    .. [1]  van der Laan, M., Polley, E. & Hubbard, A. (2007). \n",
    "            Super Learner. Statistical Applications in Genetics \n",
    "            and Molecular Biology, 6(1) \n",
    "            doi:10.2202/1544-6115.1309\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = StackedEnsembleClassifier()\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, base_estimator_type = \"logreg\", stack_layer_classifier_type = \"logreg\"):\n",
    "        \"\"\"Setup a SuperLearner classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator_types: The types of classifiers to include at the base layer\n",
    "        base_estimator_duplicates: The number of each type of classifier specified that will be trained\n",
    "        stack_layer_classifier_type: The type of classifier to include at the stack layer \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Nothing\n",
    "        \"\"\"     \n",
    "\n",
    "        # Initialise class variabels\n",
    "        self.base_estimator_type = base_estimator_type\n",
    "        self.base_estimator_type_list = list()\n",
    "        self.stack_layer_classifier_type = stack_layer_classifier_type\n",
    "        self.stack_layer_classifier = create_classifier(stack_layer_classifier_type)\n",
    "        \n",
    "    #returns k choose 2 combinations of classes where k = total number of classes\n",
    "    def get_class_combos(self, y):\n",
    "        \n",
    "        unique_classes = set(list(np.unique(y)))\n",
    "        \n",
    "        unique_combos = set()\n",
    "        \n",
    "        for i in unique_classes:\n",
    "            \n",
    "            current = set([i])\n",
    "            \n",
    "            unique_classes = unique_classes.difference(current)\n",
    "            \n",
    "            for j in unique_classes:\n",
    "              \n",
    "                if (i, j) not in unique_combos:\n",
    "                    \n",
    "                    unique_combos.add((i,j))\n",
    "                    \n",
    "        return unique_combos\n",
    "    \n",
    "\n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.class_combinations = self.get_class_combos(y)\n",
    "        \n",
    "        \"\"\"Build a SuperLearner classifier from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            The training input samples. \n",
    "        y : array-like, shape = [n_samples] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"    \n",
    "        \n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "        \n",
    "        ########################\n",
    "        # LEVEL 0\n",
    "        ########################\n",
    "        \n",
    "        # Set up the base classifeirs in the ensemble\n",
    "        self.classifiers_ = list()\n",
    "        \n",
    "        # Set up empty arrays to hold stack layer training data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=300, test_size = 0.30, train_size = 0.7)\n",
    "        self.X_stack_train = None #(dtype = float)\n",
    "        self.X_stack_train_fold = None\n",
    "        \n",
    "        #list to hold all original output values\n",
    "        self.y_stack_train = []\n",
    "        \n",
    "        samples = int(len(X_train) * 1)\n",
    "\n",
    "        for i in self.class_combinations:\n",
    "            \n",
    "            #X_samp, y_samp = resample(X_train, y_train, replace=True, random_state=randint(0,101), n_samples = samples)\n",
    "\n",
    "            #initialize arrays to hold rows corresponding to desired 2 classes\n",
    "            y_two_class = []\n",
    "            x_two_class = []\n",
    "\n",
    "            #loop through all rows in training set to identify the rows with corresponding classes\n",
    "            for count, j in enumerate(y_train):\n",
    "\n",
    "                if j in i:\n",
    "\n",
    "                    #if row class is one of 2 desired classes then append to the relevant list\n",
    "                    y_two_class.append(j)\n",
    "                    self.y_stack_train.append(j)\n",
    "                    x_two_class.append(X_train[count])\n",
    "\n",
    "\n",
    "            #convert lists to numpy arrays\n",
    "            y_two_class = np.asarray(y_two_class)\n",
    "            x_two_class = np.asarray(x_two_class)\n",
    "\n",
    "            #train a base classifier with this binary dataset\n",
    "            base_classifier = create_classifier(self.base_estimator_type)\n",
    "            base_classifier.fit(x_two_class, y_two_class)\n",
    "            self.classifiers_.append(base_classifier)\n",
    "\n",
    "            #create new dataset to train stack layer use the test set\n",
    "            y_pred = base_classifier.predict(X_test)\n",
    "\n",
    "            try:\n",
    "                #for each classifier append a new 'feature' the to stack training set\n",
    "                self.X_stack_train = np.c_[self.X_stack_train, y_pred]\n",
    "\n",
    "            except ValueError:\n",
    "\n",
    "                self.X_stack_train = y_pred\n",
    "            \n",
    "        #train the stack layer using the generated stack training set and the original ouput from y test set\n",
    "        #print(self.X_stack_train)\n",
    "        self.stack_layer_classifier.fit(self.X_stack_train, y_test)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, ].\n",
    "            The predicted class labels of the input samples. \n",
    "        \"\"\"\n",
    "        \n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "    \n",
    "        X_stack_queries = None\n",
    "              \n",
    "        # Make a prediction with each base classifier and assemble the stack layer query\n",
    "        for i, classifier in enumerate(self.classifiers_):\n",
    "            \n",
    "            y_pred = classifier.predict(X)\n",
    "            \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "        \n",
    "        # Return the prediction made by the stack layer classifier\n",
    "        return self.stack_layer_classifier.predict(X_stack_queries)\n",
    "    \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, n_labels].\n",
    "            The predicted class label probabilities of the input samples. \n",
    "        \"\"\"\n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "        \n",
    "        X_stack_queries = None\n",
    "        \n",
    "        # Make a prediction with each base classifier\n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)\n",
    "                \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "\n",
    "        # Return the prediction made by the stack layer classifier        \n",
    "        return self.stack_layer_classifier.predict_proba(X_stack_queries)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 Evaluate the Performance of the StackedEnsembleCalassifierOneVsOne Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        50\n",
      "          1       1.00      0.94      0.97        50\n",
      "          2       0.94      1.00      0.97        50\n",
      "\n",
      "avg / total       0.98      0.98      0.98       150\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>50</td>\n",
       "      <td>47</td>\n",
       "      <td>53</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2  All\n",
       "True                      \n",
       "0          50   0   0   50\n",
       "1           0  47   3   50\n",
       "2           0   0  50   50\n",
       "All        50  47  53  150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Valuation Test\n",
      "-----------------\n",
      "0.973333333333\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "clfone = StackedEnsembleClassifierOneVsOne()\n",
    "clfone.fit(iris.data, iris.target)\n",
    "y_pred = clfone.predict(iris.data)\n",
    "print(metrics.classification_report(iris.target, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(iris.target), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "gs = GridSearchCV(clfone, {\"stack_layer_classifier_type\":(\"logreg\",\"svm\",\"tree\")}, cv=5)\n",
    "\n",
    "total = 0\n",
    "#perform test 10 times and average the results\n",
    "print(\"Cross Valuation Test\")\n",
    "print(\"-----------------\")\n",
    "for i in range(0,100):\n",
    "    \n",
    "    total+=sum(cross_val_score(clfone, iris.data, iris.target, cv=5))/5\n",
    "    \n",
    "print(total/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7 Reflect on the Performance of the Different Models Evaluated"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Out of all the model created and tested the maximum cross valuation score recorded (0.973333333333) was acheived by the One to One ensemble model w/LogisticRegression as the stack classifier.\n",
    "\n",
    "Suprisingly, the cross val ensemble was the most consitently poor performing algorithms (perhaps due to human error). The One to One model performed quite well however it is important to note that the One to One algorithm implemented often performs quite poorly as the number of classes increases. 2 or 3 classes are optimal for this algorithm but dataset with a high number of target ouputs can lead to large stratification of the dataset and thus sub optimal training set sizes for the base estimators (Menahem et\tal\t2009). As such this algorithm  this likely to perform quite admirably on the iris dataset due to the low number of output classes and the evenness of the class distribution.\n",
    "\n",
    "The results of the simple classifiers such as the KNearestNeighbour and the DecisionTreeClassifier were promising. This is unsuprising due to the nature of the dataset begin used. The iris dataset is a very well structured dataset and thus generally quite easy to classify with somewhat reliable accuracy.\n",
    "\n",
    "Another interesting observation in the comparison between the basic stacked ensemble and the hold out version. Notablly, both performed very admirably when tested on the entire dataset. When performing cross validation the results were much the same. One would expect the hold out moodel to generalize better to unseen data. The reason that there was not a sizeable difference was perhaps due to the size of the original dataset. the original dataset has 150 examples so the dataset created for training the stack layer is likely to be quite small and as such, not as strong as we would like or expect. The strength of the hold out model comes from the strength of that stack classifier when compared to the basic model, if the stack layer is not trained sufficently then we may not see that power fully realized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
